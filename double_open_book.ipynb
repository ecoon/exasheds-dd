{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# makes a two-catchment open book for testing of multiple communicators and multiple subdomain solves\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import workflow.mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymetis\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400\n"
     ]
    }
   ],
   "source": [
    "xl = np.arange(-510.0, -10.0, 50.0)\n",
    "xr = -np.flipud(xl)\n",
    "\n",
    "x = np.concatenate([xl, np.array([-10.0,10.0]), xr])\n",
    "y = np.arange(-1000,1001,50)\n",
    "\n",
    "print((len(x)-1)*(len(y)-1)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,Y = np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.scatter(X.ravel(), Y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dy = 0.02\n",
    "dx = 0.05\n",
    "def elevation(x,y):\n",
    "    if x < -10:\n",
    "        z0 = (-10-x)*dx\n",
    "    elif x > 10:\n",
    "        z0 = (x-10)*dx\n",
    "    else:\n",
    "        z0 = 0.\n",
    "\n",
    "    return z0 + (y + 1000)*dy\n",
    "\n",
    "Z = np.array([elevation(xx,yy) for (xx,yy) in zip(X.ravel(), Y.ravel())]).reshape(X.shape)\n",
    "\n",
    "#plt.scatter(X.ravel(), Y.ravel(), c=Z.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 22)\n"
     ]
    }
   ],
   "source": [
    "inds = np.zeros(X.shape, 'int')\n",
    "inds.ravel()[:] = np.arange(len(X.ravel()))\n",
    "print(inds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 21, 4)\n"
     ]
    }
   ],
   "source": [
    "cells = -1 * np.ones((X.shape[0]-1, X.shape[1]-1, 4),'i')\n",
    "print(cells.shape)\n",
    "cells[:,:,0] = inds[0:-1,0:-1]\n",
    "cells[:,:,1] = inds[1:, 0:-1]\n",
    "cells[:,:,2] = inds[1:, 1:]\n",
    "cells[:,:,3] = inds[0:-1,1:]\n",
    "cells = cells.reshape((-1, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902, 3)\n"
     ]
    }
   ],
   "source": [
    "coords = np.array([X.ravel(), Y.ravel(), Z.ravel()]).transpose()\n",
    "print(coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uc = list(range(0,int(len(cells)/2)))\n",
    "dc = list(range(int(len(cells)/2),len(cells)))\n",
    "\n",
    "upstream = workflow.mesh.LabeledSet('upstream catchment surface', 10000, \"CELL\", uc)\n",
    "downstream = workflow.mesh.LabeledSet('downstream catchment surface', 10001, \"CELL\", dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "conn = [[c for c in sq] for sq in cells]\n",
    "#print(len(conn))\n",
    "print(coords.shape[1])\n",
    "m2 = workflow.mesh.Mesh2D(coords, conn, [upstream,downstream])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 3 3 3\n",
      " 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2\n",
      " 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3\n",
      " 3 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3\n",
      " 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2\n",
      " 2 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2\n",
      " 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n",
      " 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3\n",
      " 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2\n",
      " 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2\n",
      " 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# split cores across subdomain\n",
    "num_proc_total = 4\n",
    "\n",
    "partition = {'upstream':upstream,\n",
    "             'downstream':downstream}\n",
    "coloring = -np.ones(m2.num_cells(), 'i')\n",
    "\n",
    "# create reverse map from cell id to index in partition, set up data structures\n",
    "partition_reverse_maps = dict()\n",
    "partition_adjacencies = dict()\n",
    "partition_core_counts = dict()\n",
    "\n",
    "for partname, part in partition.items():\n",
    "    my_map = dict()\n",
    "    partition_reverse_maps[partname] = my_map\n",
    "    for i, ent in enumerate(part.ent_ids):\n",
    "        my_map[ent] = i\n",
    "\n",
    "    partition_adjacencies[partname] = [list() for i in range(len(part.ent_ids))]\n",
    "    partition_core_counts[partname] = int(np.round(num_proc_total * len(part.ent_ids) / m2.num_cells()))\n",
    "\n",
    "# note, we would do better to sort these somehow and give/take cores\n",
    "# to the ones furthest from their rounded values...\n",
    "init_core_count = sum(my_cores for my_cores in partition_core_counts.values())\n",
    "if (init_core_count < num_proc_total):\n",
    "    cores_to_give = num_proc_total - init_core_count\n",
    "    for partname, i in zip(partition_core_counts, range(cores_to_give)):\n",
    "        partition_core_counts[partname] += 1\n",
    "elif (init_core_count > num_proc_total):\n",
    "    cores_to_take = init_core_count - num_proc_total\n",
    "    for partname, i in zip(partition_core_counts, range(cores_to_take)):\n",
    "        partition_core_counts[partname] -= 1\n",
    "\n",
    "# create the adjacency structure of the partition's cells\n",
    "for e in m2.edges():\n",
    "    # find the cells on either side of this face\n",
    "    e_cells = m2.edge_to_cells(*e)\n",
    "    if len(e_cells) == 2:\n",
    "        # interior face, connecting two cells -- is it a cut face?\n",
    "        found = False\n",
    "        for partname, map in partition_reverse_maps.items():\n",
    "            if e_cells[0] in map and e_cells[1] in map:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            # place the adjacency in both cell lists\n",
    "            c1 = map[e_cells[0]]\n",
    "            c2 = map[e_cells[1]]\n",
    "            partition_adjacencies[partname][c1].append(c2)\n",
    "            partition_adjacencies[partname][c2].append(c1)\n",
    "\n",
    "# further partition each partition\n",
    "init_color = 0\n",
    "for partname, adjacency_info in partition_adjacencies.items():\n",
    "    n_cuts, part_coloring = pymetis.part_graph(partition_core_counts[partname], adjacency=partition_adjacencies[partname])\n",
    "    for id, color in enumerate(part_coloring):\n",
    "        coloring[partition[partname].ent_ids[id]] = color + init_color\n",
    "    init_color += partition_core_counts[partname]\n",
    "\n",
    "print(coloring)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the centroids\n",
    "#m2.plot(color=coloring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m3 = workflow.mesh.Mesh3D.extruded_Mesh2D(m2, ['constant',], [2,], [10,], [100,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upstream size: 4200\n",
      "downstream size: 4200\n"
     ]
    }
   ],
   "source": [
    "# extrude the labeled sets and add cell-based labeled sets based on upstream and downstream labels.\n",
    "upstream_cells = workflow.mesh.LabeledSet('upstream catchment', 10000, \"CELL\",\n",
    "                                          [face_id*m3.ncells_tall + j for face_id in upstream.ent_ids for j in range(m3.ncells_tall)])\n",
    "downstream_cells = workflow.mesh.LabeledSet('downstream catchment', 10001, \"CELL\",\n",
    "                                            [face_id*m3.ncells_tall + j for face_id in downstream.ent_ids for j in range(m3.ncells_tall)])\n",
    "m3.addLabeledSet(upstream_cells)\n",
    "m3.addLabeledSet(downstream_cells)\n",
    "\n",
    "print('upstream size:', len(upstream_cells.ent_ids))\n",
    "print('downstream size:', len(downstream_cells.ent_ids))\n",
    "\n",
    "# these must be written to ANOTHER file because we have no way of getting two colorings into an exodus file\n",
    "with h5py.File('subdomain_coloring.h5', 'w') as fid:\n",
    "    fid.create_dataset('upstream', data=np.array(upstream_cells.ent_ids, 'i')+1)\n",
    "    fid.create_dataset('downstream', data=np.array(downstream_cells.ent_ids, 'i')+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are using exodus.py v 1.20.0 (seacas-py3), a python wrapper of some of the exodus library.\n",
      "\n",
      "Copyright (c) 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020 National Technology &\n",
      "Engineering Solutions of Sandia, LLC (NTESS).  Under the terms of\n",
      "Contract DE-NA0003525 with NTESS, the U.S. Government retains certain\n",
      "rights in this software.\n",
      "\n",
      "Opening exodus file: double_open_book.exo\n",
      "Closing exodus file: double_open_book.exo\n"
     ]
    }
   ],
   "source": [
    "m3.write_exodus('double_open_book.exo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write a coloring file\n",
    "extruded_old_coloring = [coloring[i] for i in range(m3.num_cols) for j in range(m3.ncells_tall)]\n",
    "assert(all(np.array(extruded_old_coloring[0::m3.ncells_tall]) == np.array(coloring)))\n",
    "new_coloring = -np.ones(m3.num_cells(), 'i')\n",
    "\n",
    "# note the new coloring must be remapped as the exodus file was remapped\n",
    "for c in range(m3.num_cells()):\n",
    "    new_coloring[m3.old_to_new_elems[c]] = extruded_old_coloring[c]\n",
    "\n",
    "import struct\n",
    "with open('coloring.bin', 'wb') as fid:\n",
    "    for c in new_coloring:\n",
    "        fid.write(struct.pack('i', c))\n",
    "\n",
    "\n",
    "# this test doesn't test the remapping, because there is only one material id...\n",
    "assert(all(np.array(extruded_old_coloring) == np.array(new_coloring)))\n",
    "\n",
    "# now go partition with\n",
    "# ❯ mpiexec --oversubscribe -n 4 meshconvert --classify=1 --partition=1 --partition-method=3 double_open_book.exo 4/double_open_book.par\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/Users/uec/code/miniconda/envs/watershed_workflow_20201008/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "watershed_workflow_20201008",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "watershed_workflow_20201008"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "name": "double_open_book.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
